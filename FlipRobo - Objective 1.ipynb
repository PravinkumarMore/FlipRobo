{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internship 8 : Web Scraping Assignment using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEB SCRAPINGASSIGNMENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the following questions, you have to use BeautifulSoup to scrape different websites and collect data as per\n",
    "the requirement of the question.\n",
    "Every answer to the question should be in form of a python function which should take URL as the parameter.\n",
    "Use Jupyter Notebooks to program, upload it on your GitHub and send the link of the jupyter notebook to your\n",
    "SME. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’.\n",
    "\n",
    "\n",
    "2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of\n",
    "release) and save it in form of a CSV file.\n",
    "\n",
    "\n",
    "3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year\n",
    "of release) and save it in form of a CSV file.\n",
    "\n",
    "\n",
    "4. Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "‘www.bookpage.com’\n",
    "\n",
    "\n",
    "5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "iii) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "\n",
    "6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "\n",
    "7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The\n",
    "scraped data should include Product Name, Price, Image URL and Average Rating.\n",
    "\n",
    "\n",
    "8. Write a python program to extract information about the local weather from the National Weather Service\n",
    "website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day\n",
    "extended forecast display for the city. The data should include period, short description, temperature and\n",
    "description.\n",
    "\n",
    "\n",
    "9. Write a python program to scrape ‘software developer’ job listings from ‘Monster.com’. It should include all\n",
    "the jobs listed for the next 5 pages.\n",
    "\n",
    "\n",
    "10. Write a python program to scrape ‘data scientist’ job listings for location ‘New Delhi’ from ‘Monster.com’. It\n",
    "should include all the jobs listed for the next 5 pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 1 : "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Find the URL that we wish to Scrape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Main_Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Inspect the page"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The data is usually nested. We need to find the tag to find the desired tag. Right click on the element to be scraped and click on 'Inspect' to find tags to scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Find the data you want to extract"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Write the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure webdriver to use Chrome Browser\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the header tags :\n",
      "\n",
      "<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">Main Page</h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3 id=\"p-personal-label\">\n",
      "<span>Personal tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-namespaces-label\">\n",
      "<span>Namespaces</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-variants-label\">\n",
      "<span>Variants</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-views-label\">\n",
      "<span>Views</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-cactions-label\">\n",
      "<span>More</span>\n",
      "</h3>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-navigation-label\">\n",
      "<span>Navigation</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-interaction-label\">\n",
      "<span>Contribute</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-tb-label\">\n",
      "<span>Tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-coll-print_export-label\">\n",
      "<span>Print/export</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-wikibase-otherprojects-label\">\n",
      "<span>In other projects</span>\n",
      "</h3>\n",
      "\n",
      "<h3 id=\"p-lang-label\">\n",
      "<span>Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "titles = soup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "header_tags = print('List of all the header tags :', *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Scrapping all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
